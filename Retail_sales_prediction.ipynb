{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "O_i_v8NEhb9l",
        "HhfV-JJviCcP",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nakulcj7/Retail-sales/blob/main/Retail_sales_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    -\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Regression\n",
        "##### **Contribution**    - Individual\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "I have been provided with historical sales data for 1,115 Rossmann stores.My task is to forecast the sales for the up comming six weeks in advance and it has been mentioned that some of the store were temporarily closed for rebursment during that period sales were 0. I have two datasets.firstly i imported both the datasets.One dataset is rossman store which contains 1017209 rows and 9 columns.The dataset doesn't contain any null or duplicated values.It gives us inforamation about the type of store,sales in each store by what date through how many number of customers.Also whether the sale was affected by closure of shop on weekends or or any kind of stateholiday or schoolholiday.It also gives on how sales was affected on applying promo.The other dataset is store which has 1115 Rows and 10 Column.This dataset contains too many null values in different columns.It provides information like type of store and what is assostment level used in store,how far away is competitor from store,since how long is competitor there in the market and how often is promo applied on the store.\n",
        "\n",
        "I droped some colunms from store datset which contains too many null values and filled some fearture which contains very less amount of null values and then i merged both the datasets.I then checked for outliers and there were some columns which contained outliers and then treated them using percentile method.\n",
        "\n",
        "Then i performed EDA (univeriate,Biveriate and Multiveriate analysis) to extract some useful insights from the data.Then i performed Feature Enginering and data preprocessing in which i performed label encoding for categirical features and defined some new features also ,i calculated VIF to find out Multicolinearity between the features and selected important feature for futher analysis.Then i splitted the data in dependent and independent variables and transformed the data using Standard Scaler.Then i split the data in x_train,y_train,x_test,y_test with test size as 0.2.\n",
        "\n",
        "Then at the end i implemented Model on my data like Linear Regression,Ridge Regression,Lasso Regression,Elastic Net,Decision Tree,Random Forest and XGBoost model on my data. Based on the performance of all the models, i have selected XGBoost model as the final prediction model. The XGBoost model outperformed the other models in several key aspects, making it the preferred choice for prediction\n"
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here."
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Rossmann operates over 3,000 drug stores in 7 European Countries.Currently,Rossmann store managers are tasked with predicting their daily sales for upto six weeks in advance.Store sales are influenced by many factors,including promotions,competition,school and state holidays,seasonality,and loclity.With thousands of individual managers predicting sales based on their unique circumstance the accuracy of result can be quite varied.You are provided with historical sales data for 1,115 Rossmann stores.The task is to forecast the 'Sales' column for the test set.Note that some stores in the dataset were temporarily closed for reburisment\n"
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from numpy import math\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Mounting Google drive with colab notebook\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "ross_store=pd.read_csv('/content/drive/MyDrive/Almabetter/Rossmann Stores Data.csv')"
      ],
      "metadata": {
        "id": "RvZibUejQyef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store=pd.read_csv('/content/drive/MyDrive/Almabetter/store(1).csv')"
      ],
      "metadata": {
        "id": "JDQdtpmKRVEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "ross_store.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset first look\n",
        "store.head()"
      ],
      "metadata": {
        "id": "RN1wd4bUWZkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "\n",
        "print(f'Shape of dataset is :{ross_store.shape}')\n",
        "print(f'Our dataset contains {ross_store.index.value_counts().sum()} Rows')\n",
        "print(f'Our dataset contains {ross_store.columns.value_counts().sum()} Columns')"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#store data set Rows & column count\n",
        "print(f'Shape of dataset is :{store.shape}')\n",
        "print(f'Our dataset contains {store.index.value_counts().sum()} Rows')\n",
        "print(f'Our dataset contains {store.columns.value_counts().sum()} Column')"
      ],
      "metadata": {
        "id": "-uD1ZgPhWl1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ross_store Dataset Info\n",
        "ross_store.info()\n"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#store dataset info\n",
        "store.info()"
      ],
      "metadata": {
        "id": "JfEU3GvEW3Sx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # ross_store Dataset Duplicate Value Count\n",
        "ross_store.duplicated().any()"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ross_store dataset doesn't contain any duplicate value"
      ],
      "metadata": {
        "id": "bDxWqiWbW_d7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# store Dataset Duplicate Value Count\n",
        "store.duplicated().any()"
      ],
      "metadata": {
        "id": "uaEPrJwhXB33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Store dataset doesn't contain any duplicated values"
      ],
      "metadata": {
        "id": "XCsw6almXJAZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "ross_store.isnull().sum().sort_values(ascending=False)"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ross_store dataset doesn't contains any null values"
      ],
      "metadata": {
        "id": "7DHnCNNwXckR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "print(store.isnull().sum().sort_values(ascending=False))\n",
        "print('--'*20)\n",
        "print('Percentage Null Value')\n",
        "print(round(store.isnull().sum().sort_values(ascending=False)*100/len(store),2))"
      ],
      "metadata": {
        "id": "VMlsj_hpXhIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are too many columns which contain null values of high percentage\n",
        "\n",
        "*   Promo2SinceWeek,Promo2SinceYear,PromoInterval,CompetitionOpenSinceMonth,CompetitionOpenSinceYear contains too many null values\n",
        "\n"
      ],
      "metadata": {
        "id": "vSl5hhQLXjHK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#describe the dataset\n",
        "pd.set_option('display.float_format', lambda x: '%.0f' % x)\n",
        "percentiles = [0.01, 0.25, 0.5, 0.75, 0.95,0.99]\n",
        "ross_store.describe(percentiles=percentiles)"
      ],
      "metadata": {
        "id": "WIoTLAaIXyJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are some columns which contains outliers like Sales,customers"
      ],
      "metadata": {
        "id": "ufPkJ9iaX1_j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#describe dataset\n",
        "store.describe(percentiles=percentiles)"
      ],
      "metadata": {
        "id": "bSw3qaTuX2dq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CompetitionDistance column contain outlier"
      ],
      "metadata": {
        "id": "zPQAYD6LYGTF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.heatmap(store.isnull(),cbar=False,yticklabels=False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   \n",
        "\n",
        "    We have a dataset of rosmann company.One dataset is roaaman store which contains 1017209 rows and 9 columns.The dataset doesn't contain any null or duplicated values.It gives us inforamation about the type of store,sales in each store by what date through how many number of customers.Also whether the sale was affected by closure of shop on weekends or or any kind of stateholiday or schoolholiday.It also gives on how sales was affected on applying promo\n",
        "*   The other dataset is store which has 1115 Rows and 10 Column.This dataset contains too many null values in different columns.which needs to be taken care in upcoming steps.It provides information like type of store and what is assostment level used in store,how far away is competitor from store,since how long is competitor there in the market and how often is promo applied on the store\n",
        "\n"
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "ross_store.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store.columns"
      ],
      "metadata": {
        "id": "PYEVwR_HeDgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Most of the fields are self-explanatory. The following are descriptions for those that aren't. Store - a unique Id that represents store\n",
        "\n",
        "Sales - the turnover for any given day (this is what you are predicting)\n",
        "\n",
        "Customers - the number of customers on a given day\n",
        "\n",
        "Open - whether the store was open or not: 0 = closed, 1 = open\n",
        "\n",
        "StateHoliday - state holiday or not\n",
        "\n",
        "SchoolHoliday - School\n",
        "Holiday or not\n",
        "\n",
        "StoreType - what is the type of the store: a, b, c, d\n",
        "\n",
        "Assortment - describes an assortment level: a = basic, b = extra, c = extended\n",
        "\n",
        "CompetitionDistance - distance in meters to the nearest competitor store\n",
        "\n",
        "CompetitionOpenSince[Month/Year] - gives the approximate year and month of the time the nearest competitor was opened\n",
        "\n",
        "Promo - indicates whether a store is running a promo on that day\n",
        "\n",
        "Promo2 - store running consecutive promotion or not\n",
        "\n",
        "Promo2Since[Year/Week] - describes the year and calendar week when the store started participating in Promo2\n",
        "\n",
        "PromoInterval - describes the consecutive intervals Promo2 is started, naming the months the promotion is started a new. E.g. \"Feb,May,Aug,Nov\" means each round starts in February, May, August, November of any given year for that store.\n"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "unique_vals =ross_store.apply(lambda col: col.unique())\n",
        "print(unique_vals)\n",
        "print('*'*20)\n",
        "print('Unique Values Count')\n",
        "print(ross_store.apply(lambda col: col.nunique()))"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "state holiday cotains O instead of 0(zero)"
      ],
      "metadata": {
        "id": "oSsCba0gebSE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unique_vals =store.apply(lambda col: col.unique())\n",
        "print(unique_vals)\n",
        "print('*'*40)\n",
        "print('Unique Values Count')\n",
        "print(store.apply(lambda col: col.nunique()))"
      ],
      "metadata": {
        "id": "CrsLoJYgeenP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#dropping coluns from store dataset which contains too many null values\n",
        "store.drop(columns=['PromoInterval','Promo2SinceYear','Promo2SinceWeek','CompetitionOpenSinceYear','CompetitionOpenSinceMonth'],axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#filling null values in competitiondistance column with median\n",
        "store['CompetitionDistance'].fillna(store['CompetitionDistance'].median(),inplace=True)"
      ],
      "metadata": {
        "id": "LPwyjGVtfdEs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#merging both the dataset\n",
        "data=ross_store.merge(store,on='Store',how='left')"
      ],
      "metadata": {
        "id": "Bwz2M5lsffUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#first look of the merged dataset\n",
        "data.head()"
      ],
      "metadata": {
        "id": "3M--NTHTfisZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#shape of the dataset\n",
        "data.shape"
      ],
      "metadata": {
        "id": "es6kkLU_flmC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating year,month,week_num column from Date Column\n",
        "data['Date']=pd.to_datetime(data['Date'])\n",
        "data['year']=data['Date'].dt.year\n",
        "data['Month']=data['Date'].dt.month\n",
        "data['week_num']=data['Date'].dt.week"
      ],
      "metadata": {
        "id": "pnnw9WMCf0Us"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dropping date column from data\n",
        "data.drop(columns='Date',axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "hQ_F2jM5f5rz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Outlier Treatment\n"
      ],
      "metadata": {
        "id": "ZCD_9nkIf-f2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Now let's deal with the outliers\n",
        "plt.figure(figsize=(10,7))\n",
        "data.boxplot()\n",
        "plt.xticks(rotation='vertical')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BmUvZMqSgIAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Columns like Sales,CompetitionDistance and customers contains Outliers but CompetitionDistance contains maximum"
      ],
      "metadata": {
        "id": "odqHWm7HgNPG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#find out 90,95,99 percentile values of Competition distance column\n",
        "percentiles=[0.90,0.95,0.99]\n",
        "data['CompetitionDistance'].describe(percentiles=percentiles)"
      ],
      "metadata": {
        "id": "pXjfGFi3gQT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From this we can see that 99% value is around 36K and maximum value is around 75K,so let's consider only value around 95%"
      ],
      "metadata": {
        "id": "kYxq2qczgUGv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#find out 90,95,99 percentile values of Sales Column\n",
        "data['Sales'].describe(percentiles=percentiles)"
      ],
      "metadata": {
        "id": "Wh9q_fmcgfP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In sales Feature also outliers is there and let's consider only those value around 95%"
      ],
      "metadata": {
        "id": "g7Om6xUEgoMC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#find out 90,95,99 percentile values of Customers Column\n",
        "data['Customers'].describe(percentiles=percentiles)"
      ],
      "metadata": {
        "id": "PC-vT91Ggso2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here also let's consider value around 1400 that is around 95%"
      ],
      "metadata": {
        "id": "oxvov0fIgxQ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#let's first create copy of our dataset\n",
        "df=data.copy()"
      ],
      "metadata": {
        "id": "wuzzQZdtg06Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#shape before outlier treatment\n",
        "df.shape"
      ],
      "metadata": {
        "id": "w_sYLuG9g386"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Treating Outliers"
      ],
      "metadata": {
        "id": "yuLG0fRTg74y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#let's consider all the values in which competition distance and sales,Customers values are around 95% percentile\n",
        "df=df[df['CompetitionDistance']<20000]\n",
        "df=df[df['Customers']<1400]\n",
        "df=df[df['Sales']<13000].reset_index(drop=True)"
      ],
      "metadata": {
        "id": "op2xkb67hKKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#shape of the data after the outlier treatment\n",
        "df.shape"
      ],
      "metadata": {
        "id": "-8tHBA6yhNR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#let's convert stateholiday into state_holiday yes(1) or no(0)\n",
        "df['state_holiday'] = data['StateHoliday'].apply(lambda x: 1 if x in ['a', 'b', 'c'] else 0)"
      ],
      "metadata": {
        "id": "EZPcyMzxhQq6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#drop stateholiday column from the dataset\n",
        "df.drop(columns='StateHoliday',axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "QYCiZwbIhTxH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   first of all dropped all the columns which includes 'PromoInterval','Promo2SinceYear','Promo2SinceWeek','CompetitionOpenSinceYear','CompetitionOpenSinceMonth' from the store dataset as these contains too many null values\n",
        "\n",
        "*   After that filled null values of competitiondistance column of store dataset with median values\n",
        "\n",
        "*   Then merged both the dataset\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*   Then created Year,Month,Week_num Columns from the Date column of the dataset and then droped the Date Column\n",
        "\n",
        "\n",
        "*   Then visvalized the outliers of the data using boxplot and it was found out that columns like Competitiondistance,Sales,Customer has maximum outlier\n",
        "\n",
        "*   Then considered around 95% percentile values in order to get rid of some outliers\n",
        "*   Then converted StateHoliday Column into into another column satetholiday in which i consider 0 as No holiday and 1 as Holiday and also dropped StateHoliday Column from the dataset\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chart - 1 Sales Vs DayOfWeek"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It was mentioned that some of the shops were closed due to some rebursment so sales during that period was zero,so wel will create a dataframe that filter out those days"
      ],
      "metadata": {
        "id": "A0MMX7qABm6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#creating a dataset where ['Sales']!=0\n",
        "df1=df[df['Sales']!=0]"
      ],
      "metadata": {
        "id": "MDNISQIzBqKu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Chart 1 Sales Per Day\n",
        "#Bivariate Analysis\n",
        "ax=sns.barplot(x=df1['DayOfWeek'],y=df1['Sales'])\n",
        "plt.xlabel('Days')\n",
        "plt.ylabel('Sales')\n",
        "plt.title('Sales vs Day of week')\n",
        "for p in ax.patches:\n",
        "   ax.annotate('{:.1f}'.format(p.get_height()), (p.get_x()+0.25, p.get_height()+0.01))\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bLV7g8zdBt1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the barplot it can been seen that after day1-1 there has been decline in the sales.sufficient measures should be taken to look into this matter"
      ],
      "metadata": {
        "id": "P7Q0h9_BB2Gd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chart - 2 Sales vs Promo"
      ],
      "metadata": {
        "id": "YT5XG4l6CAUX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 Sales Vs Promo\n",
        "#Bivariate Analysis\n",
        "ax=sns.barplot(x=df['Promo'],y=df['Sales'])\n",
        "plt.title('Sales Vs Promo')\n",
        "for p in ax.patches:\n",
        "   ax.annotate('{:.1f}'.format(p.get_height()), (p.get_x()+0.25, p.get_height()+0.01))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1m7c_lB4CBJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It has been find out that the sales get's almost double when a promo is running"
      ],
      "metadata": {
        "id": "3eiMlwPwCMVW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chart - 3 Sales in Different Months"
      ],
      "metadata": {
        "id": "WNHARLoZCQbl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - Sales Over Months\n",
        "#Bivariate Analysis\n",
        "ax=sns.lineplot(x=df1['Month'],y=df1['Sales'],marker='o')\n",
        "plt.title('Sales over different Months')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rHV6akA1CTPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It can been seen that after october there has a very large growth in sales that might be due to festival season.December shows maximum sales may be because of christmas and new year"
      ],
      "metadata": {
        "id": "ohI-WF4iCYee"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chart - 4 Sales in different Stores Over Different Years"
      ],
      "metadata": {
        "id": "QyCMsrV0Cep0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 Sales Over Years in Different StoreTypes\n",
        "#Multivariate Analysis\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.barplot(x=df['year'],y=df['Sales'],hue=df['StoreType'])\n",
        "plt.title('Sales Over Years in Different StoreTypes')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gs3DmOshChHm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It was find out that Store b sales has been inceased from 2013 to 2015 and in 2013 store d has maximum sales and in remaining years store b has maximum sales"
      ],
      "metadata": {
        "id": "bi48VbBeCnp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chart - 5 Sales vs School Holiday"
      ],
      "metadata": {
        "id": "KJbn579zCr8O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 Sales vs SchoolHoliday\n",
        "#Bivaraite Analysis\n",
        "ax=sns.barplot(x=df['SchoolHoliday'],y=df['Sales'])\n",
        "plt.title('Sales vs SchoolHoliday')\n",
        "for p in ax.patches:\n",
        "   ax.annotate('{:.1f}'.format(p.get_height()), (p.get_x()+0.25, p.get_height()+0.01))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6eErVWdPCvdI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the graph it can be seen that there is a very good sales when schoolholiday is there, also good sales can be seen when there is no school Holiday,so SchoolHoliday doesn't really affect the sales"
      ],
      "metadata": {
        "id": "QszmoUDtC0Dq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Chart - 6"
      ],
      "metadata": {
        "id": "tlPh9sBRC1yL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - sales vs StateHoliday\n",
        "#Bivariate Analysis\n",
        "#plotting barplot\n",
        "ax=sns.barplot(x=df['state_holiday'],y=df['Sales'])\n",
        "plt.title('Sales vs StateHoliday')\n",
        "for p in ax.patches:\n",
        "   ax.annotate('{:.1f}'.format(p.get_height()), (p.get_x()+0.25, p.get_height()+0.01))\n",
        "plt.show()\n",
        "#plotting pie chart\n",
        "df['state_holiday'].value_counts().plot(kind='pie',autopct='%1.1f%%')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "I2QiTBO7C8zj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the barplot it can be easily seen that it doesn't matter whether there is state holiday or not there is good amount of sales on both the occassions and from the pie chart it can be seen that only 3% of sales is effected by stateholiday.So overall sales doesn't depend on stateholiday"
      ],
      "metadata": {
        "id": "p_yNqqNvDAsn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chart - 7 Sales vs Assostment Level"
      ],
      "metadata": {
        "id": "4nO-fzP1DHa6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - Sales vs AssortmentLevel in all stores\n",
        "#Multivaraite Analysis\n",
        "ax=sns.barplot(x=df['StoreType'],y=df['Sales'],hue=df['Assortment'])\n",
        "plt.title('Sales Vs Assortment Level ')\n",
        "for p in ax.patches:\n",
        "   ax.annotate('{:.1f}'.format(p.get_height()), (p.get_x()+0.25, p.get_height()+0.01))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NAB3kCK2DI6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "From the plot it can that in Store B only a and b assortment has been used and out of which assortment a got maximum sales\n",
        "\n",
        "*   Also in remaining Store only a and c assortment level has been and they got equal sales\n",
        "\n"
      ],
      "metadata": {
        "id": "d4iCCg4RDTK4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chart - 8 Sales Vs Customer"
      ],
      "metadata": {
        "id": "Y3TWzhcsDefu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 Relation between Sales and Customer\n",
        "#Bivariate Analysis\n",
        "sns.scatterplot(x=df['Customers'],y=df['Sales'])\n",
        "plt.title('Sales vs Customer')"
      ],
      "metadata": {
        "id": "Daj1uyjSDhYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It was find out from the plot that the customers and sales are positively corelated to each other i,e more customer visits the store more will be sales"
      ],
      "metadata": {
        "id": "mUOkxaBeDkxP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chart - 9"
      ],
      "metadata": {
        "id": "nqf0MZHbEDpq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code\n",
        "#Bivariate Analysis\n",
        "plt.figure(figsize=(10,7))\n",
        "sns.scatterplot(x=df['CompetitionDistance'],y=df['Sales'])\n",
        "plt.title('Sales vs CompetitionDistance')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qZrPaLFYEIHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It can been seen that most of the stores are very desely located to each other have more sales"
      ],
      "metadata": {
        "id": "_PPuU_OdEN_M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chart - 10 Sales Vs Promo 2"
      ],
      "metadata": {
        "id": "gRwPOBegESl9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 10 visualization code\n",
        "#Bivariate Analysis\n",
        "ax=sns.barplot(x=df['Promo2'],y=df['Sales'])\n",
        "plt.title('Sales vs Promo 2')\n",
        "for p in ax.patches:\n",
        "   ax.annotate('{:.1f}'.format(p.get_height()), (p.get_x()+0.25, p.get_height()+0.01))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OvQYYZtHEXc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It can be seen from the graph that Running promo continously has not been that much effective towards increasing Sales"
      ],
      "metadata": {
        "id": "VYicBFY0Ee0p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chart - 11 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "qEPoVGUhEkpi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "plt.figure(figsize=(12,5))\n",
        "corr=df.corr()\n",
        "sns.heatmap(corr,annot=True)"
      ],
      "metadata": {
        "id": "oXCaORqLEpxW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   \n",
        "\n",
        "    It can be find out that Promo,Open and customer has positive correlation with Sales means that if the shop is ruuning any promo more customers will visit the store there will be more sales\n",
        "    \n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "*   Day of week is in negative correlation with sales that means on weekends Store will be closed,there will be no sales and competiton distance also some negative correlation.\n",
        "*   State holiday has very low negative correlation with sales as sales is not affected by state holiday same case with the school holiday\n",
        "\n",
        "\n",
        "*   Multicolinearity lies between promo,customers and open column\n",
        "\n"
      ],
      "metadata": {
        "id": "8TFnDIOmEuru"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chart - 15 - Pair Plot"
      ],
      "metadata": {
        "id": "s4kh1gTTFSXA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair Plot visualization code\n",
        "sns.pairplot(df)"
      ],
      "metadata": {
        "id": "gXj22lT6FXCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the graph it can be seen what all are the features that are positively corelated with sales"
      ],
      "metadata": {
        "id": "-Z9VdQ1IFdet"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing.\n",
        "\n",
        "\n",
        "*   \n",
        "\n",
        "    Null Hypothesis: There is no relationship between Sales and Customers\n",
        "\n",
        "   \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*    Alternative Hypothesis: There is relationship between Sales and Customers\n",
        "\n",
        "*   \n",
        "\n",
        "    Null Hypothesis: There is no relationship between Sales and Promo\n",
        "\n",
        "*   Alternative Hypothesis:There is relationship between Sales and Promo\n",
        "\n",
        "\n",
        "*   Null Hypothesis: There is no relationship between Sales and DayOfWeek\n",
        "\n",
        "\n",
        "*    Alternative Hypothesis: There is relationship between Sales and DayOfWeek\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   \n",
        "\n",
        "    Null Hypothesis: There is no relationship between Sales and Customers\n",
        "    \n",
        "\n",
        "*   ALternative Hypothesis: There is relationship between Sales and Customers\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "sales = df['Sales']\n",
        "customers = df['Customers']\n",
        "\n",
        "correlation, p_value = pearsonr(sales, customers)\n",
        "\n",
        "print(\"Pearson correlation coefficient:\", correlation)\n",
        "print(\"p-value:\", p_value)\n",
        "\n",
        "alpha = 0.05\n",
        "\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis. There is a significant relationship between Sales and Customers.\")\n",
        "else:\n",
        "    print(\"Accept the null hypothesis. There is no significant relationship between Sales and Customers.\")"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to find out the correlation coefficient and P vlaue between the two features,I am using Pearson method.It helps me to find out the Corelation coeficient value which ranges from -1 and 1. A Correlation value of 1 means perfect positive correlation, whereas correlation value of -1 means strong negative relationship and a correlation value of 0 means no relationship between the features. Also the P-value helps us to find out the statistical importance of the correlation.If the p-value is less than singnificance value which is generally taken as 0.05 indicates that the correlation is significant and provides us evidence to reject the null hypothesis."
      ],
      "metadata": {
        "id": "gBhFvE7uXv8_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Null Hypothesis: There is no relationship between Sales and Promo\n",
        "\n",
        "\n",
        "\n",
        "*   ALternative Hypothesis:There is relationship between Sales and Promo\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "\n",
        "sales = df['Sales']\n",
        "promo = df['Promo']\n",
        "\n",
        "correlation, p_value = pearsonr(sales, promo)\n",
        "\n",
        "print(\"Pearson correlation coefficient:\", correlation)\n",
        "print(\"p-value:\", p_value)\n",
        "\n",
        "alpha = 0.05\n",
        "\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis. There is a significant relationship between Sales and Promo.\")\n",
        "else:\n",
        "    print(\"Accept the null hypothesis. There is no significant relationship between Sales and Promo.\")"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to find out the correlation coefficient and P vlaue between the two features,i am using Pearson method.It helps me to find out the Corelation coeficient value which ranges from -1 and 1. A Correlation value of 1 means perfect positive correlation, whereas correlation value of -1 means strong negative relationship and a correlation value of 0 means no relationship between the features. Also the P-value helps us to find out the statistical importance of the correlation.If the p-value is less than singnificance value which is generally taken as 0.05 indicates that the correlation is significant and provides us evidence to reject the null hypothesis"
      ],
      "metadata": {
        "id": "wcKy9SzoYUVX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Null Hypothesis: There is no relationship between Sales and SchoolHoliday\n",
        "\n",
        "ALternative Hypothesis: There is relationship between Sales and SchoolHoliday\n"
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "sales = df['Sales']\n",
        "Schoolholiday= df['SchoolHoliday']\n",
        "\n",
        "correlation, p_value = pearsonr(sales, Schoolholiday)\n",
        "\n",
        "print(\"Pearson correlation coefficient:\", correlation)\n",
        "print(\"p-value:\", p_value)\n",
        "\n",
        "alpha = 0.05\n",
        "\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis. There is a significant relationship between Sales and SchoolHoliday .\")\n",
        "else:\n",
        "    print(\"Accept the null hypothesis. There is no significant relationship between Sales and SchoolHoliday.\")"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to find out the correlation coefficient and P vlaue between the two features,i am using Pearson method.It helps me to find out the Corelation coeficient value which ranges from -1 and 1. A Correlation value of 1 means perfect positive correlation, whereas correlation value of -1 means strong negative relationship and a correlation value of 0 means no relationship between the features. Also the P-value helps us to find out the statistical importance of the correlation.If the p-value is less than singnificance value which is generally taken as 0.05 indicates that the correlation is significant and provides us evidence to reject the null hypothesis."
      ],
      "metadata": {
        "id": "dkrE6dLTYo4k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Textual Data Preprocessing\n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"
      ],
      "metadata": {
        "id": "Iwf50b-R2tYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Expand Contraction"
      ],
      "metadata": {
        "id": "GMQiZwjn3iu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Expand Contraction"
      ],
      "metadata": {
        "id": "PTouz10C3oNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Lower Casing"
      ],
      "metadata": {
        "id": "WVIkgGqN3qsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lower Casing"
      ],
      "metadata": {
        "id": "88JnJ1jN3w7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Removing Punctuations"
      ],
      "metadata": {
        "id": "XkPnILGE3zoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Punctuations"
      ],
      "metadata": {
        "id": "vqbBqNaA33c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Removing URLs & Removing words and digits contain digits."
      ],
      "metadata": {
        "id": "Hlsf0x5436Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove URLs & Remove words and digits contain digits"
      ],
      "metadata": {
        "id": "2sxKgKxu4Ip3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Removing Stopwords & Removing White spaces"
      ],
      "metadata": {
        "id": "mT9DMSJo4nBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Stopwords"
      ],
      "metadata": {
        "id": "T2LSJh154s8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove White spaces"
      ],
      "metadata": {
        "id": "EgLJGffy4vm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6. Rephrase Text"
      ],
      "metadata": {
        "id": "c49ITxTc407N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rephrase Text"
      ],
      "metadata": {
        "id": "foqY80Qu48N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7. Tokenization"
      ],
      "metadata": {
        "id": "OeJFEK0N496M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization"
      ],
      "metadata": {
        "id": "ijx1rUOS5CUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8. Text Normalization"
      ],
      "metadata": {
        "id": "9ExmJH0g5HBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing Text (i.e., Stemming, Lemmatization etc.)"
      ],
      "metadata": {
        "id": "AIJ1a-Zc5PY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text normalization technique have you used and why?"
      ],
      "metadata": {
        "id": "cJNqERVU536h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Z9jKVxE06BC1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 9. Part of speech tagging"
      ],
      "metadata": {
        "id": "k5UmGsbsOxih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# POS Taging"
      ],
      "metadata": {
        "id": "btT3ZJBAO6Ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 10. Text Vectorization"
      ],
      "metadata": {
        "id": "T0VqWOYE6DLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorizing Text"
      ],
      "metadata": {
        "id": "yBRtdhth6JDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text vectorization technique have you used and why?"
      ],
      "metadata": {
        "id": "qBMux9mC6MCf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "su2EnbCh6UKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select your features wisely to avoid overfitting"
      ],
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "pEMng2IbBLp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "fGgaEstsBnaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Your data"
      ],
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling your data"
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "kexQrXU-DjzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DImensionality Reduction (If needed)"
      ],
      "metadata": {
        "id": "kQfvxBBHDvCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"
      ],
      "metadata": {
        "id": "T5CmagL3EC8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "ZKr75IDuEM7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely."
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why?"
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Handling Imbalanced Dataset"
      ],
      "metadata": {
        "id": "P1XJ9OREExlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ],
      "metadata": {
        "id": "VFOzZv6IFROw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "GeKDIv7pFgcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Imbalanced Dataset (If needed)"
      ],
      "metadata": {
        "id": "nQsRhhZLFiDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"
      ],
      "metadata": {
        "id": "TIqpNgepFxVj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "qbet1HwdGDTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "negyGRa7fxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "OaLui8CcfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart"
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "lQMffxkwpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "MzVzZC6opx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the File"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the File and predict unseen data."
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write the conclusion here."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}